# Mareen - Voice Assistant ğŸ™ï¸

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Platform](https://img.shields.io/badge/platform-Windows-lightgrey.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

> *A privacy-focused voice assistant with immersive 3D orb UI, powered by local AI*

## Overview
Mareen is a calm, immersive, voice-first AI assistant featuring a glowing particle sphere interface. Experience the future of private, offline AI interaction with beautiful visualizations and natural voice conversations.

**Powered by:**
- ğŸ§  **Ollama** - Local LLM processing (model `j`)
- ğŸ¤ **Vosk** - Offline speech recognition
- ğŸ”Š **EdgeTTS / pyttsx3** - Natural text-to-speech
- ğŸ¨ **pywebview** - Stunning 3D Voice Orb UI

## âœ¨ Features

- ğŸ™ï¸ **Voice Interaction** - Natural speech recognition with real-time transcription streaming
- ğŸŒ **Offline First** - Complete privacy with local LLM processing (no data leaves your machine)
- ğŸ‡®ğŸ‡³ **Hindi Support** - Native Hindi language understanding and responses
- ğŸ”® **3D Orb UI** - Immersive particle sphere visualization with dynamic color states
- ğŸ¯ **System Control** - Open applications, find files, and execute commands
- ğŸ§  **Smart Intent** - Understands natural language commands and context
- ğŸ”Š **Text-to-Speech** - Natural voice responses with emotion
- âš¡ **Lightweight** - Runs efficiently on local hardware
- ğŸ”’ **Privacy Focused** - No cloud dependencies, no telemetry
- ğŸ’¾ **Conversation Memory** - Persistent logging of all sessions and conversations
- ğŸ›¡ï¸ **Soul Protection** - Immutable personality protected from prompt injection attacks
- ğŸ§  **RAG System** - Retrieval-Augmented Generation for context-aware responses

## Architecture

```
Microphone â†’ Vosk STT â†’ Intent Parser â†’ Ollama LLM â†’ Edge TTS â†’ Speaker
                              â†“
                      System Commands
                      File Operations
```

## Screenshots

### ğŸ”® Main Interface - Glowing Orb States
*Coming soon: Screenshots of idle, listening, and speaking states*

<!-- Uncomment when screenshots are added
![Idle State](docs/screenshots/orb-idle.png)
![Listening Mode](docs/screenshots/orb-listening.png)
![Speaking Mode](docs/screenshots/orb-speaking.png)
-->

## Prerequisites

1. **Python 3.10+** - Ensure you have a compatible Python version installed
2. **Ollama** - Download and install from [ollama.com](https://ollama.com)
   - Pull a model: `ollama pull llama2` or create your custom model `j`
   - Verify installation: `ollama list`
3. **Microphone** - Set as default recording device in system settings
4. **Git** - For cloning the repository (optional)

## Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/saxil/mareen.git
cd mareen
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

**Note:** If you encounter errors with `PyAudio`:
- Windows: Download pre-built wheel from [unofficial binaries](https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio)
- Linux: `sudo apt-get install portaudio19-dev python3-pyaudio`
- macOS: `brew install portaudio && pip install pyaudio`

### 3ï¸âƒ£ Setup Vosk Model (Optional but Recommended)
For better offline speech recognition:
```bash
python scripts/setup_model.py
```
This downloads the Vosk model for English and Hindi support.

### 4ï¸âƒ£ Configure Ollama
Ensure your LLM model is ready:
```bash
ollama pull llama2
# Or use your custom model 'j'
```

## Usage

### Starting Mareen
```bash
python src/main.py
```

### Voice Commands
Once the orb appears and turns **yellow** (listening), try:
- ğŸ’¬ **General conversation:** "Hello", "Tell me a joke", "What's the weather?"
- ğŸš€ **System commands:** 
  - "Open calculator"
  - "Open notepad"
  - "Open Chrome"
  - "Find files named report"
- ğŸ›‘ **Exit:** "Stop", "Exit", "Goodbye"

### UI States
- ğŸŸ¡ **Amber** - Idle / Ready
- ğŸŸ¢ **Yellow** - Listening
- ğŸ”µ **Blue** - Speaking / Responding
- ğŸŸ£ **Purple** - Processing / Thinking

## ğŸ’¾ Memory System

Mareen now includes a comprehensive memory system that logs every conversation and session to a local SQLite database.

### Features
- ğŸ“ **Automatic Logging** - Every message (user and assistant) is saved automatically
- ğŸ•’ **Session Tracking** - Each conversation session is tracked with timestamps
- ğŸ” **Search Capability** - Search through all past conversations
- ğŸ“Š **Statistics** - View usage statistics and patterns
- ğŸ“¤ **Export** - Export sessions to JSON format for backup or analysis
â”œâ”€â”€ intent.py       # Command parser
â”‚   â”‚   â””â”€â”€ memory.py       # Conversation memory system
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ system.py       # System commands
â”‚   â”‚   â””â”€â”€ files.py        # File operations
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ index.html      # 3D Orb interface
â”‚       â””â”€â”€ gui.py          # GUI components
â”œâ”€â”€ models/                  # Vosk models directory
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup_model.py      # Model downloader
â”œâ”€â”€ view_memory.py          # Memory viewer utility
â”œâ”€â”€ memory.db               # Conversation database (auto-created)
python view_memory.py stats

# List all sessions
python view_memory.py sessions

# View specific session
python view_memory.py view <session_id>

# Search conversations
python view_memory.py search "hello"

# Export session to JSON
python view_memory.py export <session_id> output.json
```

### Memory Database Location
All conversations are stored in `memory.db` in the project root directory. This file is created automatically on first run.

### Privacy Note
Your conversation history is stored **locally only** on your machine. No data is sent to external servers. You can delete `memory.db` at any time to clear your history.

## ğŸ›¡ï¸ Soul Protection System

Mareen's personality is protected by a **Soul System** that prevents prompt injection attacks and personality manipulation.

### What is the Soul?
The soul ([soul.md](soul.md)) is Mareen's core identity file that defines:
- Personality traits and behavior
- Language preferences (Hindi)
- Response guidelines
- Protected instructions that cannot be overridden

### Injection Protection
Mareen automatically detects and blocks attempts to:
- Override system instructions
- Change personality or identity
- Ignore core directives
- Pretend to be other AI assistants
- Execute harmful commands through manipulation

### Testing Protection
```bash
# Test the soul protection system
python test_soul.py
```

### How It Works
1. **Soul Loading**: System prompt loaded from `soul.md` (immutable)
2. **Input Scanning**: Every user input checked for 34+ injection patterns
3. **Automatic Blocking**: Injection attempts rejected with polite Hindi responses
4. **Memory Logging**: All injection attempts logged for security review

### Why This Matters
Prevents users from:
- "Jailbreaking" the assistant
- Making Mareen act inappropriately
- Bypassing safety guidelines
- Compromising the user experience for others

## ğŸ§  RAG System (Retrieval-Augmented Generation)

Mareen uses **RAG** to remember past conversations and provide contextual responses based on your history.

### What is RAG?
RAG combines your conversation memory with AI responses:
1. When you ask a question, Mareen searches past conversations
2. Relevant context is retrieved and added to the prompt
3. The LLM generates a response aware of your history
4. You get personalized, context-aware answers

### Features
- ğŸ” **Semantic Search** - Finds relevant past conversations (not just keywords)
- â° **Time Decay** - Recent conversations weighted higher
- ğŸ¯ **Smart Context** - Top 3 most relevant memories included
- ğŸ’¾ **Embedding Cache** - Fast retrieval with cached vectors
- ğŸ”„ **Fallback Mode** - Works with keyword matching if embeddings unavailable

### How It Works
```python
User: "How do I learn Python?"
  â†“
RAG searches memory for similar past conversations
  â†“
Finds: "Can you help me with programming?"
  â†“
Adds context to LLM prompt
  â†“
Mareen: "à¤œà¥ˆà¤¸à¤¾ à¤•à¤¿ à¤®à¥ˆà¤‚à¤¨à¥‡ à¤ªà¤¹à¤²à¥‡ à¤¬à¤¤à¤¾à¤¯à¤¾ à¤¥à¤¾ programming à¤•à¥‡ à¤²à¤¿à¤..."
```

### Testing RAG
```bash
python test_rag.py
```

### Optional: Semantic Embeddings
For better context matching, install sentence-transformers:
```bash
pip install sentence-transformers
```

Without it, RAG uses keyword matching (still effective but less nuanced).

## Project Structure

```
mareen/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Application entry point
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ llm.py          # Ollama LLM integration
â”‚   â”‚   â”œâ”€â”€ stt.py          # Speech-to-text (Vosk)
â”‚   â”‚   â”œâ”€â”€ tts.py          # Text-to-speech
â”‚   â”‚   â”œâ”€â”€ intent.py       # Command parser
â”‚   â”‚   â”œâ”€â”€ memory.py       # Conversation memory system
   â”‚   â”œâ”€â”€ soul.py         # Soul protection system
   â”‚   â””â”€â”€ rag.py          # RAG retrieval system
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ system.py       # System commands
â”‚   â”‚   â””â”€â”€ files.py        # File operations
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ index.html      # 3D Orb interface
â”‚       â””â”€â”€ gui.py          # GUI components
â”œâ”€â”€ models/                  # Vosk models directory
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup_model.py      # Model downloader
â”œâ”€â”€ soul.md                 # Protected personality definition
â”œâ”€â”€ view_memory.py          # Memory viewer utility
â”œâ”€â”€ test_soul.py            # Soul protection tests
â”œâ”€â”€ test_rag.py             # RAG system tests
â”œâ”€â”€ memory.db               # Conversation database (auto-created)
â”œâ”€â”€ embeddings_cache.pkl    # RAG embeddings cache (auto-created)
â””â”€â”€ requirements.txt        # Python dependencies
```

## Configuration

### Customizing Personality
Edit [soul.md](soul.md) to customize:
- AI personality and language
- Response style and tone
- System prompts
- Behavioral guidelines

**Note**: After editing `soul.md`, restart the application or use the reload feature.

### Developer Options
Edit [src/core/llm.py](src/core/llm.py) for:
- Model selection (default: 'j2')
- Advanced LLM parameters

## Troubleshooting

**Issue:** Microphone not detected
- **Solution:** Check system audio settings and set default input device

**Issue:** Ollama connection failed
- **Solution:** Ensure Ollama is running: `ollama serve`

**Issue:** Poor speech recognition
- **Solution:** Use Vosk models for better offline accuracy

**Issue:** Application won't start
- **Solution:** Check Python version (3.10+) and reinstall dependencies

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## Roadmap

- [x] Context-aware conversations with memory
- [x] Soul protection against prompt injection
- [x] RAG system for contextual responses
- [ ] Wake word detection ("Hey Mareen")
- [ ] Multi-language support (Spanish, French, etc.)
- [ ] Plugin system for custom commands
- [ ] Mobile companion app
- [ ] Voice cloning for personalized TTS
- [ ] Integration with smart home devices
- [ ] Memory-based context retention across sessions
- [ ] Advanced injection detection with ML

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **Ollama** - For making local LLMs accessible
- **Vosk** - For offline speech recognition
- **pywebview** - For the beautiful UI framework
- **Edge TTS** - For natural voice synthesis

## Support

â­ Star this repository if you find it helpful!

For issues and questions, please open an [issue](https://github.com/saxil/mareen/issues).

---

**Made with â¤ï¸ for privacy-conscious AI enthusiasts**
